{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13808249,"sourceType":"datasetVersion","datasetId":8792504}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1>Libraries</h1>","metadata":{}},{"cell_type":"code","source":"# ===================== LIBRARIES =====================\nimport pandas as pd\nimport numpy as np\nimport joblib\nimport os\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom catboost import CatBoostClassifier\n\nfrom sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n\n# ===================== CONFIG =====================\nRANDOM_STATE = 42\n#TARGET = \"loan_paid_back\"\ndataset = \"/kaggle/input/loan-pay-back-dataset-2025-2026-credit-to-kaggle/train.csv\"\n\n# ===================== LOAD DATA =====================\ndf = pd.read_csv(dataset)\n\nprint(\"Dataset shape:\", df.shape)\nprint(\"Target distribution:\\n\", df[TARGET].value_counts())\n\n\n# ===================== DROP ID & TARGET =====================\nX = df.drop(columns=[TARGET, \"id\"], errors=\"ignore\")\ny = df[TARGET]\n\n# ===================== COLUMN TYPES =====================\ncategorical_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\nnumerical_cols = X.select_dtypes(exclude=[\"object\"]).columns.tolist()\n\nprint(\"Categorical columns:\", categorical_cols)\nprint(\"Numerical columns:\", numerical_cols)\n\n# ===================== ENCODING =====================\nX_encoded = X.copy()\nlabel_encoders = {}\n\nfor col in categorical_cols:\n    le = LabelEncoder()\n    X_encoded[col] = le.fit_transform(X_encoded[col])\n    label_encoders[col] = le\n\nfeature_columns = X_encoded.columns.tolist()\n\n# ===================== SPLIT =====================\nX_train, X_test, y_train, y_test = train_test_split(\n    X_encoded,\n    y,\n    test_size=0.2,\n    stratify=y,\n    random_state=RANDOM_STATE\n)\n\n# ===================== SCALING =====================\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# ===================== MODELS =====================\nmodels = {\n    \"Logistic Regression\": LogisticRegression(\n        max_iter=2000,\n        class_weight=\"balanced\",\n        n_jobs=-1,\n        random_state=RANDOM_STATE\n    ),\n\n    \"Random Forest\": RandomForestClassifier(\n        n_estimators=1000,\n        max_depth=12,\n        min_samples_split=5,\n        min_samples_leaf=3,\n        class_weight=\"balanced\",\n        n_jobs=-1,\n        random_state=RANDOM_STATE\n    ),\n\n    \"CatBoost\": CatBoostClassifier(\n        iterations=100,\n        learning_rate=0.03,\n        depth=7,\n        loss_function=\"Logloss\",\n        eval_metric=\"AUC\",\n        auto_class_weights=\"Balanced\",\n        l2_leaf_reg=6,\n        random_seed=RANDOM_STATE,\n        verbose=0\n    )\n}\n\n# ===================== TRAIN & EVALUATE =====================\nresults = {}\ntrained_models = {}\n\nfor name, model in models.items():\n\n    if name == \"Logistic Regression\":\n        model.fit(X_train_scaled, y_train)\n        preds = model.predict(X_test_scaled)\n        probs = model.predict_proba(X_test_scaled)[:, 1]\n\n    elif name == \"Random Forest\":\n        model.fit(X_train, y_train)\n        preds = model.predict(X_test)\n        probs = model.predict_proba(X_test)[:, 1]\n\n    else:  # CatBoost\n        model.fit(X_train, y_train)\n        preds = model.predict(X_test)\n        probs = model.predict_proba(X_test)[:, 1]\n\n    acc = accuracy_score(y_test, preds)\n    auc = roc_auc_score(y_test, probs)\n\n    results[name] = {\"accuracy\": acc, \"auc\": auc}\n    trained_models[name] = model\n\n    print(f\"\\n===== {name} =====\")\n    print(f\"Accuracy: {acc:.4f}\")\n    print(f\"AUC: {auc:.4f}\")\n    print(classification_report(y_test, preds))\n\n# ===================== SELECT BEST MODEL =====================\nbest_model_name = max(results, key=lambda k: results[k][\"auc\"])\nbest_model = trained_models[best_model_name]\n\nprint(\"\\n BEST MODEL SELECTED:\", best_model_name)\nprint(\"Best AUC:\", results[best_model_name][\"auc\"])\n\n# ===================== SAVE ARTIFACTS =====================\njoblib.dump(best_model, \"best_model.pkl\")\njoblib.dump(scaler, \"scaler.pkl\")\njoblib.dump(label_encoders, \"label_encoders.pkl\")\njoblib.dump(feature_columns, \"feature_columns.pkl\")\n\nprint(\"\\n Files saved successfully:\")\nprint(\" - best_model.pkl\")\nprint(\" - scaler.pkl\")\nprint(\" - label_encoders.pkl\")\nprint(\" - feature_columns.pkl\")\n","metadata":{"execution":{"iopub.status.busy":"2025-12-29T11:24:56.943061Z","iopub.execute_input":"2025-12-29T11:24:56.943751Z","iopub.status.idle":"2025-12-29T11:30:02.988758Z","shell.execute_reply.started":"2025-12-29T11:24:56.943720Z","shell.execute_reply":"2025-12-29T11:30:02.988069Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Dataset shape: (593994, 13)\nTarget distribution:\n loan_paid_back\n1.0    474494\n0.0    119500\nName: count, dtype: int64\nCategorical columns: ['gender', 'marital_status', 'education_level', 'employment_status', 'loan_purpose', 'grade_subgrade']\nNumerical columns: ['annual_income', 'debt_to_income_ratio', 'credit_score', 'loan_amount', 'interest_rate']\n\n===== Logistic Regression =====\nAccuracy: 0.8300\nAUC: 0.8919\n              precision    recall  f1-score   support\n\n         0.0       0.56      0.77      0.65     23900\n         1.0       0.94      0.85      0.89     94899\n\n    accuracy                           0.83    118799\n   macro avg       0.75      0.81      0.77    118799\nweighted avg       0.86      0.83      0.84    118799\n\n\n===== Random Forest =====\nAccuracy: 0.8681\nAUC: 0.9137\n              precision    recall  f1-score   support\n\n         0.0       0.64      0.77      0.70     23900\n         1.0       0.94      0.89      0.92     94899\n\n    accuracy                           0.87    118799\n   macro avg       0.79      0.83      0.81    118799\nweighted avg       0.88      0.87      0.87    118799\n\n\n===== CatBoost =====\nAccuracy: 0.8618\nAUC: 0.9115\n              precision    recall  f1-score   support\n\n         0.0       0.63      0.77      0.69     23900\n         1.0       0.94      0.88      0.91     94899\n\n    accuracy                           0.86    118799\n   macro avg       0.78      0.83      0.80    118799\nweighted avg       0.88      0.86      0.87    118799\n\n\n BEST MODEL SELECTED: Random Forest\nBest AUC: 0.9137150498828065\n\n Files saved successfully:\n - best_model.pkl\n - scaler.pkl\n - label_encoders.pkl\n - feature_columns.pkl\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}